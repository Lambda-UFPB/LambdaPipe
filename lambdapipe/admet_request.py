import requests
from aiohttp import ClientSession, ClientTimeout
import asyncio
import timeit
from bs4 import BeautifulSoup
import urllib3
from exceptions import BadAdmetSmilesError
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


protocol = "https"
url = f"https://admetmesh.scbdd.com/service/screening/cal"
post_url = ''
download_url = ''
SSL = True
dict_smiles_list = []


def check_ssl():
    """Check if the SSL certificate is valid"""
    global protocol
    global url
    global post_url
    global download_url
    global SSL
    post_url = url
    try:
        requests.get(url, verify=True)
    except requests.exceptions.SSLError:
        url = f"http://admetmesh.scbdd.com/service/screening/cal"
        protocol = "http"
        SSL = False
    url = f"{protocol}://admetmesh.scbdd.com/service/screening/cal"
    download_url = f"{protocol}://admetmesh.scbdd.com"


def get_smiles_string(best_molecules_dict: dict):
    smiles_list = [mol_data['smiles'] for mol_data in best_molecules_dict.values()]
    if len(smiles_list) > 5:
        num_sublists = (len(smiles_list) + 4) // 5
        smiles_sublists = [smiles_list[i*5:(i+1)*5] for i in range(num_sublists)]
        smiles_strings = ['\r\n'.join(sublist) for sublist in smiles_sublists]
        return smiles_strings, smiles_list
    else:
        smiles_string = '\r\n'.join(smiles_list)
        return smiles_string, smiles_list


async def get_csv(session: ClientSession, smiles: str, index: int):
    """Get url for csv file generated by the admetlab portal for the smiles"""
    global url
    global post_url
    global SSL
    global dict_smiles_list
    path = ''
    async with session.get(url=url, ssl=SSL) as get_response:
        csrftoken = get_response.cookies["csrftoken"].value
    payload = {
        "csrfmiddlewaretoken": csrftoken,
        "smiles-list": smiles,
        "method": "2"
    }
    headers = dict(Referer=post_url)
    cookies = get_response.cookies
    last_smile_removed = ''
    soup = None

    for i, smile in enumerate(smiles.split('\r\n')):
        smiles_separated = smiles.split('\r\n')
        try:
            async with session.post(post_url, data=payload, headers=headers, cookies=cookies, ssl=SSL) as r:
                if r.status != 200:
                    raise BadAdmetSmilesError()
                text = await r.text()
                soup = BeautifulSoup(text, "html.parser")
                break

        except BadAdmetSmilesError:
            smiles_separated.remove(smile)
            smiles_together = '\r\n'.join(smiles_separated)
            payload["smiles-list"] = smiles_together
            last_smile_removed = smile
    if last_smile_removed:
        dict_smiles_list.remove(last_smile_removed)
    if soup:
        for a in soup.find_all('a', href=True):
            if '/tmp' in a['href']:
                path = a['href']
    if not path:
        for smile in smiles.split('\r\n'):
            try:
                dict_smiles_list.remove(smile)
            except ValueError:
                pass

    csv = f'admetcsv_{index}.csv'

    return path, csv


async def download(session, path: str, csv, output_folder_path: str):
    global download_url
    async with session.get(f"{download_url}{path}", ssl=SSL, timeout=99999) as d_response:
        content = await d_response.text()
    with open(f'{output_folder_path}/admet/{csv}', 'w') as csv_file:
        csv_file.write(content)


async def run_admet_request(best_molecules_dict: dict, output_folder_path: str):
    global dict_smiles_list
    check_ssl()
    smiles_strings, dict_smiles_list = get_smiles_string(best_molecules_dict)
    timeout = ClientTimeout(total=120000)
    async with ClientSession(timeout=timeout) as session:
        tasks = []
        for index, smiles_divided_group in enumerate(smiles_strings):
            task = asyncio.ensure_future(get_csv(session, smiles_divided_group, index))
            tasks.append(task)
        responses = await asyncio.gather(*tasks)
        download_tasks = [download(session, path, csv, output_folder_path) for path, csv in responses if path]
        await asyncio.gather(*download_tasks)
    return dict_smiles_list


if __name__ == "__main__":
    output_folder = "/home/kdunorat/lambdapipe_results/testefinal"
    dict_final = ''

    """
    smiles_string, dict_smiles_list = get_smiles_string(dict_final)
    for i, g in enumerate(smiles_string):
        if i == 43:
            smiles_teste = g
            break
    async def teste(smiles_teste):
        global dict_smiles_list
        async with ClientSession() as session_teste:
            path, csv, last = await get_csv(session_teste, smiles_teste, 43)
        return path, csv, dict_smiles_list, last
    check_ssl()
    path, csv, dict_smiles_list2, last = asyncio.run(teste(smiles_teste))
     """

    start_time = timeit.default_timer()
    dict_smiles = asyncio.run(asyncio.wait_for(run_admet_request(dict_final, output_folder), timeout=120000))
    end_time = timeit.default_timer()
    execution_time = end_time - start_time
    print(f"The function took {execution_time} seconds to complete")
    print(dict_smiles)



