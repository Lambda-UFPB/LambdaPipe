import requests
from requests.exceptions import ChunkedEncodingError
from bs4 import BeautifulSoup
import time


def get_csv(smiles):
    """Get url for csv archive generated by the admetlab portal for the smiles. Also indicates which ones were
    deemed invalid by the site."""
    path = ''
    invalids = []
    url = f"https://admetmesh.scbdd.com/service/evaluation/cal"
    client = requests.session()
    client.get(url=url, timeout=10)
    csrftoken = client.cookies["csrftoken"]
    payload = {
        "csrfmiddlewaretoken": csrftoken,
        "smiles": smiles,
        "method": "1"
    }

    
    r = client.post(url, data=payload, headers=dict(Referer=url))
    soup = BeautifulSoup(r.content, "html.parser")

    # Checks if the site considered all smiles invalid and, if so, raises an TypeError
    if soup.find_all(class_="alert alert-warning"):
        raise TypeError('All smiles are invalid')

    tags = soup.find_all("li", class_="list-group-item text-center")
    for invalid in tags:
        invalids.append(invalid.text)
    for a in soup.find_all('a', href=True):
        if '/tmp' in a['href']:
            path = a['href']
    csv = path.split('/')
    csv = csv[-1]

    return path, csv, invalids

def download(path, csv):
    content = requests.get(f"https://admetmesh.scbdd.com{path}").text
    with open(f'admet_results/{csv}', 'w') as csv_file:
        csv_file.write(content)

def run(smiles):
    path, csv, invalids = get_csv(smiles)
    download(path, csv)
    

if __name__ == '__main__':
    smiles = '[H]N1CC(N2CCC3(CC2)COC(C)C3N([H])[H])=NC2=C1C(N1CCCC3=C1C=CC(C1=NOC=N1)=C3)=NN2[H]'
    start = time.time()
    run(smiles)
    print(time.time() - start)
